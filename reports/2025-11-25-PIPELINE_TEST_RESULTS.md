# Doctown Pipeline Test Report

**Date**: 2025-11-25T12:35:25-07:00
**Test**: Full Pipeline (build-llm)
**Status**: ✅ PASSED

## Test Configuration

- **Input**: https://github.com/xandwr/localdoc
- **Extra Args**: <none>
- **LLM Enabled**: true
- **Output Directory**: /home/xander/Documents/doctown-v6/output

## Pipeline Stages

The following stages were executed:

1. ✓ Domain detection & ingestion (pluggable ingestors)
2. ✓ Universal chunk extraction (standardized IR)
3. ✓ Embedding generation
4. ✓ Semantic graph building
5. ✓ LLM documentation generation
6. ✓ Docpack packaging
7. ✓ Verification

## Output Files

```
```

## Environment

- **Python**: /home/xander/Documents/doctown-v6/doctown/python/venv/bin/python --version 2>&1 || echo "Not available"
- **OPENAI_API_KEY**: Set
- **Working Directory**: /home/xander/Documents/doctown-v6

## Notes

All pipeline stages completed successfully. The upgraded pipeline with LLM documentation generation is working correctly.

---
*Report generated by test_pipeline.sh*
